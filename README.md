# ğŸ”¬ KAN-NAFNet: A Hybrid Framework for Image Super-Resolution

This project integrates two powerful components:
- **KAN (Kernel Activation Network):** A dynamic multi-activation neural module with adaptive activation function selection.
- **NAFNet:** A lightweight convolutional architecture for image enhancement and denoising.

The integration enables patch-wise image super-resolution, guided by learned activation performance and perceptual loss optimization.

---

## ğŸš€ Features

âœ… **Patch-based super-resolution** with learned KAN upscaling  
âœ… **Dynamic activation selection** from over 30 activation functions  
âœ… **Fusion with NAFNet** for feature refinement and detail restoration  
âœ… **Custom dataset support** with automatic HRâ†’LR conversion  
âœ… **Support for advanced loss functions:** Charbonnier & Perceptual Loss  
âœ… **Activation performance tracking** for adaptive training strategies  

---

## ğŸ§  Architecture Overview

| Module | Purpose |
|--------|---------|
| `ActivationModule` | Provides dozens of activation functions, including Swish, Mish, SQNL, ISRLU, etc. |
| `KANLinear` | Linear layer with multiple parallel activation paths and learned weights |
| `KANNetwork` | A stack of `KANLinear` layers forming a flexible MLP |
| `KANeural` | Processes image patches and upsamples them using KAN logic |
| `NAFNet` | Lightweight image restoration network with residual and gating mechanisms |
| `KANNAFNetIntegrated` | Full hybrid model combining multiple KAN blocks + NAFNet |
| `SRDataset` | Custom dataset that dynamically creates LR images from HR originals |
| `CharbonnierLoss` | Smooth L1 loss for robustness to outliers |
| `PerceptualLoss` | Uses VGG19 features to optimize visual quality |
| `DynamicActivationRegistry` | Tracks activation performance and recommends top activations |

---

## ğŸ“¦ Dependencies

```bash
pip install torch torchvision numpy pillow matplotlib tqdm h5py pyyaml
```

---

## ğŸ’¡ Example Usage

```python
from model import KANNAFNetIntegrated
import torch

model = KANNAFNetIntegrated(in_channels=3)
input_tensor = torch.randn(1, 3, 64, 64)
output = model(input_tensor)
print(output.shape)  # Should output high-resolution image tensor
```

---

## ğŸ§ª Dataset Preparation

Your high-resolution image folder should contain `.png`, `.jpg`, or `.bmp` files:

```python
train_loader, val_loader = create_dataloaders(
    hr_dir='path/to/HR', 
    batch_size=8, 
    patch_size=128,
    lr_scale=4
)
```

Each HR image will be downscaled using bicubic interpolation to simulate LR inputs.

---

## ğŸ¯ Training Objective

You can combine multiple loss functions:

```python
loss1 = CharbonnierLoss()(output, target)
loss2 = PerceptualLoss()(output, target)
total_loss = loss1 + 0.1 * loss2
```

---

## ğŸ“ˆ Activation Tracking

Use the `DynamicActivationRegistry` to keep track of the most successful activation functions and dynamically select the top-performing ones during training.

```python
registry = DynamicActivationRegistry()
registry.update_metrics("swish", 0.03)
top_acts = registry.get_top_activations(n=5)
```

---

## ğŸ§± Applications

- Super-resolution of natural images (x2, x4 scaling)
- Denoising and artifact reduction
- Activation function analysis and dynamic architecture tuning

---

## ğŸ“Œ Future Improvements

- Add support for attention-based fusion between KAN and NAFNet
- Learnable activation function replacement schedules
- Benchmarking on standard datasets like DIV2K and Set5

---


### ğŸ” Super-Resolution Workflow Tree (KAN + NAFNet)

Super-Resolution Pipeline
â”‚
â”œâ”€â”€ ğŸ“¥ Load High-Resolution (HR) Images
â”‚ â””â”€â”€ from user-specified folder (e.g., ./data/HR_Images)
â”‚
â”œâ”€â”€ ğŸ”„ Preprocessing
â”‚ â”œâ”€â”€ Apply random flip, rotation (for data augmentation)
â”‚ â””â”€â”€ Extract HR patches and downscale to get LR patches
â”‚
â”œâ”€â”€ ğŸ§  Model Architecture
â”‚ â”œâ”€â”€ ğŸ”— KAN Blocks
â”‚ â”‚ â””â”€â”€ Approximate HR pixel functions using adaptive activation networks
â”‚ â”œâ”€â”€ ğŸ”§ NAFNet Blocks
â”‚ â”‚ â””â”€â”€ Denoise and resolve pixel congestion in upsampled images
â”‚ â””â”€â”€ ğŸ”€ Combined Output
â”‚ â””â”€â”€ Clean, high-quality SR image
â”‚
â”œâ”€â”€ ğŸ¯ Loss Functions
â”‚ â”œâ”€â”€ Charbonnier Loss (pixel-wise robust loss)
â”‚ â””â”€â”€ Perceptual Loss (feature-level comparison via VGG)
â”‚
â”œâ”€â”€ ğŸ“š Training Phase
â”‚ â”œâ”€â”€ Loop over epochs and batches
â”‚ â”œâ”€â”€ Compute losses and update model weights
â”‚ â””â”€â”€ Periodically update activation function usage stats
â”‚
â”œâ”€â”€ ğŸ“ˆ Validation
â”‚ â””â”€â”€ Compare predicted SR images with HR ground truth (using unseen LR inputs)
â”‚
â””â”€â”€ ğŸ’¾ Output
â”œâ”€â”€ Save trained model
â”œâ”€â”€ Log losses and performance
â””â”€â”€ Export SR validation samples

Copy
Edit


























## ğŸ“œ License

This project is licensed under the [MIT License](https://opensource.org/licenses/MIT).

