# ğŸ”¬ KAN-NAFNet: A Hybrid Framework for Image Super-Resolution

This project integrates two powerful components:
- **KAN (Kernel Activation Network):** A dynamic multi-activation neural module with adaptive activation function selection.
- **NAFNet:** A lightweight convolutional architecture for image enhancement and denoising.

The integration enables patch-wise image super-resolution, guided by learned activation performance and perceptual loss optimization.

---

## ğŸš€ Features

âœ… **Patch-based super-resolution** with learned KAN upscaling  
âœ… **Dynamic activation selection** from over 30 activation functions  
âœ… **Fusion with NAFNet** for feature refinement and detail restoration  
âœ… **Custom dataset support** with automatic HRâ†’LR conversion  
âœ… **Support for advanced loss functions:** Charbonnier & Perceptual Loss  
âœ… **Activation performance tracking** for adaptive training strategies  

---

## ğŸ§  Architecture Overview

| Module | Purpose |
|--------|---------|
| `ActivationModule` | Provides dozens of activation functions, including Swish, Mish, SQNL, ISRLU, etc. |
| `KANLinear` | Linear layer with multiple parallel activation paths and learned weights |
| `KANNetwork` | A stack of `KANLinear` layers forming a flexible MLP |
| `KANeural` | Processes image patches and upsamples them using KAN logic |
| `NAFNet` | Lightweight image restoration network with residual and gating mechanisms |
| `KANNAFNetIntegrated` | Full hybrid model combining multiple KAN blocks + NAFNet |
| `SRDataset` | Custom dataset that dynamically creates LR images from HR originals |
| `CharbonnierLoss` | Smooth L1 loss for robustness to outliers |
| `PerceptualLoss` | Uses VGG19 features to optimize visual quality |
| `DynamicActivationRegistry` | Tracks activation performance and recommends top activations |

---

## ğŸ“¦ Dependencies

```bash
pip install torch torchvision numpy pillow matplotlib tqdm h5py pyyaml
```

---

## ğŸ’¡ Example Usage

```python
from model import KANNAFNetIntegrated
import torch

model = KANNAFNetIntegrated(in_channels=3)
input_tensor = torch.randn(1, 3, 64, 64)
output = model(input_tensor)
print(output.shape)  # Should output high-resolution image tensor
```

---

## ğŸ§ª Dataset Preparation

Your high-resolution image folder should contain `.png`, `.jpg`, or `.bmp` files:

```python
train_loader, val_loader = create_dataloaders(
    hr_dir='path/to/HR', 
    batch_size=8, 
    patch_size=128,
    lr_scale=4
)
```

Each HR image will be downscaled using bicubic interpolation to simulate LR inputs.

---

## ğŸ¯ Training Objective

You can combine multiple loss functions:

```python
loss1 = CharbonnierLoss()(output, target)
loss2 = PerceptualLoss()(output, target)
total_loss = loss1 + 0.1 * loss2
```

---

## ğŸ“ˆ Activation Tracking

Use the `DynamicActivationRegistry` to keep track of the most successful activation functions and dynamically select the top-performing ones during training.

```python
registry = DynamicActivationRegistry()
registry.update_metrics("swish", 0.03)
top_acts = registry.get_top_activations(n=5)
```

---

## ğŸ§± Applications

- Super-resolution of natural images (x2, x4 scaling)
- Denoising and artifact reduction
- Activation function analysis and dynamic architecture tuning

---

## ğŸ“Œ Future Improvements

- Add support for attention-based fusion between KAN and NAFNet
- Learnable activation function replacement schedules
- Benchmarking on standard datasets like DIV2K and Set5

---

### ğŸ” Super-Resolution Workflow Tree (KAN + NAFNet)

Super-Resolution Pipeline
â”‚
â”œâ”€â”€ Load High-Resolution (HR) Images
â”‚ â””â”€â”€ From user-specified folder (e.g. ./data/HR_Images)
â”‚
â”œâ”€â”€ Preprocessing
â”‚ â”œâ”€â”€ Apply random flip and rotation
â”‚ â””â”€â”€ Downsample HR images to get LR images
â”‚
â”œâ”€â”€ KAN + NAFNet Model
â”‚ â”œâ”€â”€ KAN Block: approximates pixel-value functions with adaptive activations
â”‚ â”œâ”€â”€ NAFNet Block: denoises and resolves pixel congestion
â”‚ â””â”€â”€ Combined SR output
â”‚
â”œâ”€â”€ Loss Functions
â”‚ â”œâ”€â”€ Charbonnier Loss (robust pixel-wise)
â”‚ â””â”€â”€ Perceptual Loss (VGG-based feature distance)
â”‚
â”œâ”€â”€ Training Loop
â”‚ â”œâ”€â”€ Load batches
â”‚ â”œâ”€â”€ Compute losses
â”‚ â”œâ”€â”€ Update model weights
â”‚ â””â”€â”€ Update activation usage stats
â”‚
â”œâ”€â”€ Validation
â”‚ â””â”€â”€ Compare SR prediction with original HR using LR input
â”‚
â””â”€â”€ Save Outputs
â”œâ”€â”€ Trained model weights
â””â”€â”€ SR prediction samples

Copy
Edit
#######
























## ğŸ“œ License

This project is licensed under the [MIT License](https://opensource.org/licenses/MIT).

